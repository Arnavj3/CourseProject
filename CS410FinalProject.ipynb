{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS410FinalProject.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMu_rvvXL_PA"
      },
      "source": [
        "**Requirement for project**\n",
        "\n",
        "Only necessary to run once."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riMCy9U7qEei",
        "outputId": "7e6939d1-e919-429f-ad54-e0638f146eeb"
      },
      "source": [
        "!pip install lyricsgenius\n",
        "!pip install nltk"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting lyricsgenius\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/c1/b7d56971a43e430214727daf774623d8edd0c13fe7bac1f484d0934af29b/lyricsgenius-2.0.2-py3-none-any.whl (46kB)\n",
            "\r\u001b[K     |███████▏                        | 10kB 16.0MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 20kB 19.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 30kB 18.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 40kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 4.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from lyricsgenius) (2.23.0)\n",
            "Requirement already satisfied: beautifulsoup4>=4.6.0 in /usr/local/lib/python3.6/dist-packages (from lyricsgenius) (4.6.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->lyricsgenius) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->lyricsgenius) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->lyricsgenius) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->lyricsgenius) (1.24.3)\n",
            "Installing collected packages: lyricsgenius\n",
            "Successfully installed lyricsgenius-2.0.2\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyO01L78t3Uq",
        "outputId": "e6007af5-1194-401c-dcb2-b9d11908828e"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk import pos_tag\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import nltk.data\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from collections import defaultdict\n",
        "import operator\n",
        "import lyricsgenius\n",
        "import string\n",
        "import requests\n",
        "import urllib\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "from bs4 import BeautifulSoup\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount your Drive to the Colab VM.\n",
        "drive.mount(\"/content/drive\")\n",
        "PROFANITY_TEXT_URL = \"https://www.cs.cmu.edu/~biglou/resources/bad-words.txt\"\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xb5xhVT2QCn0",
        "outputId": "f4adf93e-5816-4225-d4a3-61498f6f519f"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgcHCDX4McXu"
      },
      "source": [
        "**We will now scrape the names of artists in the Billboard hot 100**\n",
        "\n",
        "Given a year, this function will scrape billboard for the hot 100 songs and save artist names for that year and return a set with these names added. We use beautiful soup to clean our scraped data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ve3HNJWWNBwE"
      },
      "source": [
        "def get_billboard_year_songs(year):\n",
        "    url = 'https://en.m.wikipedia.org/wiki/Billboard_Year-End_Hot_100_singles_of_' + str(year)\n",
        "    req = requests.get(url)\n",
        "    bs4 = BeautifulSoup(req.text, 'lxml')\n",
        "    rows = bs4.find('table').find_all('tr')[1:]\n",
        "    # rows = rows\n",
        "    artists = set()\n",
        "    songLocator = ['td', 'th']\n",
        "    for row in rows:\n",
        "        cols = row.find_all(songLocator)\n",
        "        cols = [t.text.strip().strip('\"') for t in cols]\n",
        "        try:\n",
        "            artists.add(cols[2])\n",
        "        except:\n",
        "            continue\n",
        "    return (artists)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DB9_lbfchpS3"
      },
      "source": [
        "**We get artist names for our desired range of years**\n",
        "\n",
        "We iterate over our desired range of years and gather artist names that we have scraped. We then remove duplicates by doing a union operation across all gathered artist name sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsryiZQYQVYf",
        "outputId": "862e9afd-bbb8-4fcb-9122-a8f19f11511b"
      },
      "source": [
        "START_YEAR = 1980\n",
        "END_YEAR = 2020\n",
        "artistSetList = []\n",
        "for year in range(START_YEAR, END_YEAR + 1):\n",
        "  artistSetList.append(get_billboard_year_songs(year))\n",
        "artistNames = set().union(*artistSetList)\n",
        "print(\"We will be collecting songs for \" + str(len(artistNames)) + \" artists\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We will be collecting songs for 1983 artists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1b4Hrijcf_f"
      },
      "source": [
        "**The below script retrieves our songs for us**\n",
        "\n",
        "We use the lyricsgenius package to query the Genius API. We clean the artist string to remove features and strange formatting issues. \n",
        "\n",
        "We then query the genius API to retrieve an artist object from which we retrieve 25 songs per artist. Along with this, we also gather additional metadata points and the song lyrics.\n",
        "\n",
        "Once we complete collecting songs for an artist, we periodically save this gathered data in a CSV file by mounting our drive. We will use this csv file henceforth and there is no need to run this script again.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "pdMu7MuCp-gz",
        "outputId": "72048bcd-3fac-4f8e-f5f9-2a790e36fb2a"
      },
      "source": [
        "genius = lyricsgenius.Genius(\"at79YK0XXNNSWi25Dh4EtJUke1t5s0lQY-5KqwMdWBZNthInRQibKkLrvAhY5x2z\")\n",
        "artists = list(artistNames)\n",
        "songData = []\n",
        "\n",
        "for artist in artists:\n",
        "  artist = artist.split('featuring')\n",
        "  try:\n",
        "    artistObj = genius.search_artist(artist[0].strip(), max_songs = 25, sort=\"popularity\")\n",
        "    for song in artistObj.songs:\n",
        "      songData.append({\"Song\" : song.title, \"Artist\": song.artist, \"Year\": song.year, \"Album\": song.album, \"Lyric\": song.lyrics})\n",
        "    with open('/gdrive/My Drive/dataset.csv', 'w') as f:\n",
        "      pd.DataFrame(songData).to_csv(f)\n",
        "  except:\n",
        "    continue\n",
        "\n",
        "\n",
        "dataset = pd.DataFrame(songData)\n",
        "with open('/gdrive/My Drive/dataset.csv', 'w') as f:\n",
        "      dataset.to_csv(f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-558cb2d28661>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgenius\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlyricsgenius\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenius\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"at79YK0XXNNSWi25Dh4EtJUke1t5s0lQY-5KqwMdWBZNthInRQibKkLrvAhY5x2z\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0martists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martistNames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msongData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0martist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'artistNames' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CQHrAnteFq4"
      },
      "source": [
        "**We will now read the saved CSV file and save it into dataframe**\n",
        "\n",
        "We use pandas for easier manupilation of data. This format is scalable and if we decide to mine more data in the future on songs and add it to the csv file, it can seamlessly be loaded into a new dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBgZ7uOCw2kj"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/dataset.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Szn17ncRdkLQ"
      },
      "source": [
        "**We will begin cleaning the retrieved data**\n",
        "\n",
        "Most artist, album and song names are in the correct format for the purposes of this project. We need to clean the lyrics to prepare them for sentiment analysis. We do this by removing stopwords, fixing formatting issues and getting rid of unnecesary details such as verse labels etc. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOBGHCvQeaBq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "d772a320-3b5c-4f0b-ef04-13dfdd85a4d3"
      },
      "source": [
        "df.drop_duplicates()\n",
        "df.Lyric = df.Lyric.fillna(\"\")\n",
        "df.Lyric = df.Lyric.str.lower()\n",
        "df.Song = df.Song.str.lower()\n",
        "df.Artist = df.Artist.str.lower()\n",
        "df.Album = df.Album.str.lower()\n",
        "df.Year = df.Year.str.slice(0, 4)\n",
        "df.Lyric = df.Lyric.str.replace(r\"\\[.*\\]\", \"\")\n",
        "df.Lyric = df.Lyric.str.replace(r\"\\{.*\\}\", \"\")\n",
        "df.Lyric = df.Lyric.str.replace(r\"\\(\", \"\")\n",
        "df.Lyric = df.Lyric.str.replace(r\"\\)\", \"\")\n",
        "df.Lyric = df.Lyric.str.replace(r\"\\n\", \" \")\n",
        "df.Lyric = df.Lyric.str.replace(r\"\\\\\", \"\")\n",
        "df.Lyric = df.Lyric.str.strip()\n",
        "df.Lyric = df.Lyric.str.replace(r\"instrumental|intro|guitar|solo\",\"\")\n",
        "df.Lyric = df.Lyric.str.replace(\"\\n\",\" \").str.replace(r\"[^\\w\\d'\\s]+\",\"\").str.replace(\"efil ym fo flah\",\"\")\n",
        "stop = stopwords.words('english')\n",
        "df['SentimentLyrics'] = df.Lyric\n",
        "df.Lyric = df.Lyric.apply(lambda x: [item for item in x.split() if item not in stop])\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Song</th>\n",
              "      <th>Artist</th>\n",
              "      <th>Year</th>\n",
              "      <th>Album</th>\n",
              "      <th>Lyric</th>\n",
              "      <th>SentimentLyrics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>nobody knows</td>\n",
              "      <td>juelz santana</td>\n",
              "      <td>2013</td>\n",
              "      <td>god will’n</td>\n",
              "      <td>[nobody, knows, go, put, inside, shoes, got, f...</td>\n",
              "      <td>nobody knows what i go through if you can put ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>soft</td>\n",
              "      <td>juelz santana</td>\n",
              "      <td>2013</td>\n",
              "      <td>god will’n</td>\n",
              "      <td>[say, im, comin, hard, huh, cheaheh, say, nigg...</td>\n",
              "      <td>they say im comin too hard huh cheaheh i say t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>everything is good</td>\n",
              "      <td>juelz santana</td>\n",
              "      <td>2013</td>\n",
              "      <td>god will’n</td>\n",
              "      <td>[wiz, khalifa, aight, hehehehehe, yeah, uhh, f...</td>\n",
              "      <td>wiz khalifa aight hehehehehe yeah uhh   feeli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>time ticking</td>\n",
              "      <td>juelz santana</td>\n",
              "      <td>2016</td>\n",
              "      <td>the get back</td>\n",
              "      <td>[getting, money, hating, real, nigga, celebrat...</td>\n",
              "      <td>we just getting to the money why they hating t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>black out</td>\n",
              "      <td>juelz santana</td>\n",
              "      <td>2013</td>\n",
              "      <td>god will’n</td>\n",
              "      <td>[fly, nigga, i'm, taking, whooo, uh, flyfly, n...</td>\n",
              "      <td>fly nigga i'm taking off whooo uh flyfly nigga...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                    SentimentLyrics\n",
              "0           0  ...  nobody knows what i go through if you can put ...\n",
              "1           1  ...  they say im comin too hard huh cheaheh i say t...\n",
              "2           2  ...   wiz khalifa aight hehehehehe yeah uhh   feeli...\n",
              "3           3  ...  we just getting to the money why they hating t...\n",
              "4           4  ...  fly nigga i'm taking off whooo uh flyfly nigga...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-JHapufpmmt"
      },
      "source": [
        "**We will now conduct sentiment analysis on our lyrics column**\n",
        "\n",
        "We use VADER (Valence Aware Dictionary and sEntiment Reasoner) of the NLKT Python Library is a lexicon and rule-based sentiment analysis tool. \n",
        "\n",
        "We will be using VADER's Compound Metric that calculates the sum of all the lexicon rating, which is normalized between -1(max limit of negativity) and 1(max limit of positivity)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "SHKjJeXJmNRW",
        "outputId": "74e299a7-d6bb-4dc0-be1a-492a81161525"
      },
      "source": [
        "compoundScores = []\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "for i in df.index:\n",
        "    scores = sid.polarity_scores(df.SentimentLyrics.iloc[i])\n",
        "    compoundScores.append(scores['compound'])\n",
        "df['Sentiment'] = compoundScores\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Song</th>\n",
              "      <th>Artist</th>\n",
              "      <th>Year</th>\n",
              "      <th>Album</th>\n",
              "      <th>Lyric</th>\n",
              "      <th>SentimentLyrics</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>nobody knows</td>\n",
              "      <td>juelz santana</td>\n",
              "      <td>2013</td>\n",
              "      <td>god will’n</td>\n",
              "      <td>[nobody, knows, go, put, inside, shoes, got, f...</td>\n",
              "      <td>nobody knows what i go through if you can put ...</td>\n",
              "      <td>0.9966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>soft</td>\n",
              "      <td>juelz santana</td>\n",
              "      <td>2013</td>\n",
              "      <td>god will’n</td>\n",
              "      <td>[say, im, comin, hard, huh, cheaheh, say, nigg...</td>\n",
              "      <td>they say im comin too hard huh cheaheh i say t...</td>\n",
              "      <td>-0.9991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>everything is good</td>\n",
              "      <td>juelz santana</td>\n",
              "      <td>2013</td>\n",
              "      <td>god will’n</td>\n",
              "      <td>[wiz, khalifa, aight, hehehehehe, yeah, uhh, f...</td>\n",
              "      <td>wiz khalifa aight hehehehehe yeah uhh   feeli...</td>\n",
              "      <td>0.9781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>time ticking</td>\n",
              "      <td>juelz santana</td>\n",
              "      <td>2016</td>\n",
              "      <td>the get back</td>\n",
              "      <td>[getting, money, hating, real, nigga, celebrat...</td>\n",
              "      <td>we just getting to the money why they hating t...</td>\n",
              "      <td>-0.9887</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>black out</td>\n",
              "      <td>juelz santana</td>\n",
              "      <td>2013</td>\n",
              "      <td>god will’n</td>\n",
              "      <td>[fly, nigga, i'm, taking, whooo, uh, flyfly, n...</td>\n",
              "      <td>fly nigga i'm taking off whooo uh flyfly nigga...</td>\n",
              "      <td>-0.9987</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ... Sentiment\n",
              "0           0  ...    0.9966\n",
              "1           1  ...   -0.9991\n",
              "2           2  ...    0.9781\n",
              "3           3  ...   -0.9887\n",
              "4           4  ...   -0.9987\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBXJpsOkGVFZ"
      },
      "source": [
        "**We will now work to assign a profanity score to each song**\n",
        "\n",
        "We do this by using a compiled list of profane words and counting occurances of these words within our lyrics. We will then normalize this count and add it as a column to our dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aV2Eb4kuFuJ"
      },
      "source": [
        "data = urllib.request.urlopen(PROFANITY_TEXT_URL)\n",
        "bytetext = data.read()\n",
        "profanityString = str(bytetext, 'utf-8')\n",
        "profanitySet = set(profanityString.split())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkM-ortPF1Lg"
      },
      "source": [
        "def getProfanityCount(lyricWords):\n",
        "  profanityCount = 0\n",
        "  for word in lyricWords:\n",
        "    if word in profanitySet:\n",
        "      profanityCount += 1\n",
        "  return profanityCount"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "AOat32PnGRFZ",
        "outputId": "d714901a-6fbf-4989-995e-cf4f733c84f3"
      },
      "source": [
        "counter = 0\n",
        "profanityCount = []\n",
        "for i in df.index:\n",
        "  profanityCount.append(getProfanityCount(df.Lyric.iloc[i]))\n",
        "df['Profanity'] = profanityCount\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Song</th>\n",
              "      <th>Artist</th>\n",
              "      <th>Year</th>\n",
              "      <th>Album</th>\n",
              "      <th>Lyric</th>\n",
              "      <th>SentimentLyrics</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Profanity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>nobody knows</td>\n",
              "      <td>juelz santana</td>\n",
              "      <td>2013</td>\n",
              "      <td>god will’n</td>\n",
              "      <td>[nobody, knows, go, put, inside, shoes, got, f...</td>\n",
              "      <td>nobody knows what i go through if you can put ...</td>\n",
              "      <td>0.9966</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>soft</td>\n",
              "      <td>juelz santana</td>\n",
              "      <td>2013</td>\n",
              "      <td>god will’n</td>\n",
              "      <td>[say, im, comin, hard, huh, cheaheh, say, nigg...</td>\n",
              "      <td>they say im comin too hard huh cheaheh i say t...</td>\n",
              "      <td>-0.9991</td>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>everything is good</td>\n",
              "      <td>juelz santana</td>\n",
              "      <td>2013</td>\n",
              "      <td>god will’n</td>\n",
              "      <td>[wiz, khalifa, aight, hehehehehe, yeah, uhh, f...</td>\n",
              "      <td>wiz khalifa aight hehehehehe yeah uhh   feeli...</td>\n",
              "      <td>0.9781</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>time ticking</td>\n",
              "      <td>juelz santana</td>\n",
              "      <td>2016</td>\n",
              "      <td>the get back</td>\n",
              "      <td>[getting, money, hating, real, nigga, celebrat...</td>\n",
              "      <td>we just getting to the money why they hating t...</td>\n",
              "      <td>-0.9887</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>black out</td>\n",
              "      <td>juelz santana</td>\n",
              "      <td>2013</td>\n",
              "      <td>god will’n</td>\n",
              "      <td>[fly, nigga, i'm, taking, whooo, uh, flyfly, n...</td>\n",
              "      <td>fly nigga i'm taking off whooo uh flyfly nigga...</td>\n",
              "      <td>-0.9987</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                Song  ... Sentiment Profanity\n",
              "0           0        nobody knows  ...    0.9966         9\n",
              "1           1                soft  ...   -0.9991        54\n",
              "2           2  everything is good  ...    0.9781        21\n",
              "3           3        time ticking  ...   -0.9887        39\n",
              "4           4           black out  ...   -0.9987        40\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0X051mpam6Ro"
      },
      "source": [
        "def filterbyartist(df, artistname):\r\n",
        "  return df.loc[df['Artist'] == artistname.lower()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aGD-v1OqcBn"
      },
      "source": [
        "def filterbyalbum(df, albumname):\r\n",
        "  return df.loc[df['Album'] == albumname.lower()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o--sf_A9rEEM"
      },
      "source": [
        "def filterbyyear(df, startyear, endyear):\r\n",
        "  #format of year - string as YYYY-MM-DD\r\n",
        "  return df.loc[df['Year'] >= float(startyear) and df['Year'] <= float(endyear)]"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGGhXAz9u2ut"
      },
      "source": [
        "**We will be using the following metric to evaluate sentiment** \n",
        "\n",
        "positive sentiment : (compound score >= 0.05)\n",
        "\n",
        "neutral sentiment : (compound score > -0.05) and (compound score < 0.05)\n",
        "\n",
        "negative sentiment : (compound score <= -0.05)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPtV8cz2sL3F"
      },
      "source": [
        "def filterbysentiment(df, word):\r\n",
        "  happyset = {\"joyful\", \"cheerful\", \"delightful\", \"pleasing\", \"jolly\", \"merry\", \"lighthearted\", \"ecstatic\", \"gleeful\", \"happy\"}\r\n",
        "  sadset = {\"unhappy\", \"sorrowful\", \"downhearted\", \"miserable\", \"gloomy\", \"woeful\", \"melancholy\", \"despressing\", \"mournful\", \"distressing\", \"sad\"}\r\n",
        "  \r\n",
        "  if word in happyset:\r\n",
        "    return df.loc[df['Sentiment'] >= 0]\r\n",
        "\r\n",
        "  elif word in sadset:\r\n",
        "    return df.loc[df['Sentiment'] < 0]\r\n",
        "\r\n",
        "  #SNF -  Sentiment not found\r\n",
        "  else:\r\n",
        "    return df"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CB5ocqGUwAqj"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/unnormalizedDataset.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhcCP4nijcOl"
      },
      "source": [
        "**The following cell will pre-process TF-IDF for similarity calculations**\n",
        "\n",
        "TF-IDF = Term Frequency (TF) * Inverse Document Frequency (IDF)\n",
        "\n",
        "We will be using this formula and applying the functions to the cleaned lyrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTbsWS7QWy5-"
      },
      "source": [
        "df = df.drop_duplicates(subset='Song', keep=\"first\")\r\n",
        "import ast \r\n",
        "\r\n",
        "\r\n",
        "# Create Vocabulary\r\n",
        "vocabulary = set()\r\n",
        "for doc in df.Lyric:\r\n",
        "    res = ast.literal_eval(doc)\r\n",
        "    vocabulary.update(res)\r\n",
        "\r\n",
        "vocabulary = list(vocabulary)\r\n",
        "\r\n",
        "tfidf = TfidfVectorizer(sublinear_tf = True, stop_words='english', vocabulary = vocabulary)\r\n",
        "tfidf_tran = tfidf.fit_transform(df.Lyric)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhOLdYu1tIHi"
      },
      "source": [
        "def gen_vector_T(tokens):\n",
        "    Q = np.zeros((len(vocabulary)))\n",
        "    x = tfidf.transform(tokens)\n",
        "    for token in tokens[0].split(','):\n",
        "        try:\n",
        "            ind = vocabulary.index(token)\n",
        "            Q[ind] = x[0, tfidf.vocabulary_[token]]\n",
        "        except:\n",
        "            pass\n",
        "    return Q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7tSu1k7rn1N"
      },
      "source": [
        "def cosine_sim(a, b):\n",
        "    cos_sim = np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b))\n",
        "    return cos_sim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeQ1KLHUrqUO"
      },
      "source": [
        "def cosine_similarity_T(k, query):\n",
        "    preprocessed_query = preprocessed_query = re.sub(\"\\W+\", \" \", query).strip()\n",
        "    tokens = word_tokenize(str(preprocessed_query))\n",
        "    q_df = pd.DataFrame(columns=['q_clean'])\n",
        "    q_df.loc[0,'q_clean'] = tokens\n",
        "    q_df['q_clean'] = ','.join(q_df.q_clean[0])\n",
        "    d_cosines = []\n",
        "    query_vector = gen_vector_T(q_df['q_clean'])\n",
        "    for d in tfidf_tran.A:\n",
        "        d_cosines.append(cosine_sim(query_vector, d))\n",
        "    out = np.array(d_cosines).argsort()[-k:][::-1]\n",
        "    a = pd.DataFrame()\n",
        "    for i,index in enumerate(out):\n",
        "        a.loc[i,'Song'] = df['Song'][index]\n",
        "    for j, simScore in enumerate(d_cosines[-k:][::-1]):\n",
        "        a.loc[j,'Score'] = simScore\n",
        "    return a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "MPU_FiZ_xYFL",
        "outputId": "4e1cb231-9616-4a58-d4e7-5ca7ae98adf1"
      },
      "source": [
        "cosine_similarity_T(10, 'guns fuck kill')\n",
        "# df\n",
        "# print(tfidf_tran)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Song</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>t. mata</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gammer gerten’s needle</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i robot</td>\n",
              "      <td>0.063680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sirius</td>\n",
              "      <td>0.013781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>jazzy</td>\n",
              "      <td>0.032928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>choir practice</td>\n",
              "      <td>0.025346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>axel f</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>memories</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>the one after</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Song     Score\n",
              "0                 t. mata  0.000000\n",
              "1  gammer gerten’s needle  0.000000\n",
              "2                 i robot  0.063680\n",
              "3                  sirius  0.013781\n",
              "4                   jazzy  0.032928\n",
              "5          choir practice  0.025346\n",
              "6                  axel f  0.000000\n",
              "7                memories  0.000000\n",
              "8                     NaN  0.000000\n",
              "9           the one after  0.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1UPU1N1xdHc"
      },
      "source": [
        "cols_to_norm = ['Profanity']\r\n",
        "df[cols_to_norm] = df[cols_to_norm].apply(lambda x: (x - x.min()) / (x.max() - x.min()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPfcjjlSvIlO",
        "outputId": "62a6eef0-183f-4be1-802c-8ac1c0eb89bc"
      },
      "source": [
        "\r\n",
        "df['Profanity'].median()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.009900990099009901"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USElf8iyD_Ur"
      },
      "source": [
        "def filterbyprofanity(df, prof):\r\n",
        "  if prof == '0':\r\n",
        "    return df.loc[df['Profanity'] < 0.009900990099009901]\r\n",
        "  \r\n",
        "  elif prof == '1':\r\n",
        "    return df.loc[df['Profanity'] >= 0.009900990099009901]\r\n",
        "\r\n",
        "  else:\r\n",
        "    return df"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quuo-7TqEEMC"
      },
      "source": [
        "def lyricSearch(df, lyrics):\r\n",
        "  search = [lyrics]\r\n",
        "  return df.loc[df['Lyric'].str.contains(lyrics.lower()) ]\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upGsiTTCuelQ"
      },
      "source": [
        "def"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjxWpNMper_P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "outputId": "d3bd1f2b-0702-4eb6-c28e-1e9966f29b2b"
      },
      "source": [
        "lyricSearch(df,'dick')"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Song</th>\n",
              "      <th>Artist</th>\n",
              "      <th>Year</th>\n",
              "      <th>Album</th>\n",
              "      <th>Lyric</th>\n",
              "      <th>SentimentLyrics</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Profanity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>soft</td>\n",
              "      <td>juelz santana</td>\n",
              "      <td>2013.0</td>\n",
              "      <td>god will’n</td>\n",
              "      <td>['say', 'im', 'comin', 'hard', 'huh', 'cheaheh...</td>\n",
              "      <td>they say im comin too hard huh cheaheh i say t...</td>\n",
              "      <td>-0.9991</td>\n",
              "      <td>0.267327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>black out</td>\n",
              "      <td>juelz santana</td>\n",
              "      <td>2013.0</td>\n",
              "      <td>god will’n</td>\n",
              "      <td>['fly', 'nigga', \"i'm\", 'taking', 'whooo', 'uh...</td>\n",
              "      <td>fly nigga i'm taking off whooo uh flyfly nigga...</td>\n",
              "      <td>-0.9987</td>\n",
              "      <td>0.198020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>my will</td>\n",
              "      <td>juelz santana</td>\n",
              "      <td>2013.0</td>\n",
              "      <td>god will’n</td>\n",
              "      <td>['hope', 'son', 'learn', 'like', 'die', 'tonig...</td>\n",
              "      <td>i hope my son learn to be not like me if i die...</td>\n",
              "      <td>-0.9958</td>\n",
              "      <td>0.153465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>25</td>\n",
              "      <td>damn!</td>\n",
              "      <td>youngbloodz (hip hop)</td>\n",
              "      <td>2003.0</td>\n",
              "      <td>drankin’ patnaz</td>\n",
              "      <td>['calling', 'come', 'back', 'streets', 'sean',...</td>\n",
              "      <td>they calling me to come back to the streets se...</td>\n",
              "      <td>0.9992</td>\n",
              "      <td>0.420792</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>27</td>\n",
              "      <td>whatchu lookin’ at</td>\n",
              "      <td>youngbloodz (hip hop)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>drankin’ patnaz</td>\n",
              "      <td>['yeah', 'yeah', 'yeah', 'whatchu', 'lookin', ...</td>\n",
              "      <td>yeah yeah yeah whatchu lookin at nigga whatchu...</td>\n",
              "      <td>-0.9978</td>\n",
              "      <td>0.242574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9154</th>\n",
              "      <td>11024</td>\n",
              "      <td>fuck what happens tonight</td>\n",
              "      <td>french montana</td>\n",
              "      <td>2013.0</td>\n",
              "      <td>excuse my french</td>\n",
              "      <td>['fuck', 'ho', 'shit', 'fuck', 'fuck', 'boys',...</td>\n",
              "      <td>fuck all that ho shit fuck all you fuck boys b...</td>\n",
              "      <td>-0.9995</td>\n",
              "      <td>0.366337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9257</th>\n",
              "      <td>11167</td>\n",
              "      <td>one minute man</td>\n",
              "      <td>missy elliott</td>\n",
              "      <td>2001.0</td>\n",
              "      <td>miss e ...so addictive</td>\n",
              "      <td>['ooh', 'want', 'need', \"can't\", 'stand', 'min...</td>\n",
              "      <td>ooh i don't want i don't need i can't stand no...</td>\n",
              "      <td>0.4645</td>\n",
              "      <td>0.064356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9260</th>\n",
              "      <td>11170</td>\n",
              "      <td>sock it 2 me</td>\n",
              "      <td>missy elliott</td>\n",
              "      <td>1997.0</td>\n",
              "      <td>supa dupa fly</td>\n",
              "      <td>['hehe', 'nigga', \"i'm\", 'nasty', 'looking', '...</td>\n",
              "      <td>hehe nigga i'm nasty do it do it do it do it d...</td>\n",
              "      <td>-0.9879</td>\n",
              "      <td>0.143564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9261</th>\n",
              "      <td>11171</td>\n",
              "      <td>busa rhyme</td>\n",
              "      <td>missy elliott</td>\n",
              "      <td>1999.0</td>\n",
              "      <td>da real world</td>\n",
              "      <td>['uh', 'slim', 'shady', 'uh', 'slim', 'shady',...</td>\n",
              "      <td>uh slim shady uh slim shady uh slim shady uh y...</td>\n",
              "      <td>-0.9981</td>\n",
              "      <td>0.193069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9262</th>\n",
              "      <td>11172</td>\n",
              "      <td>one minute man (remix)</td>\n",
              "      <td>missy elliott</td>\n",
              "      <td>2001.0</td>\n",
              "      <td>miss e ...so addictive</td>\n",
              "      <td>['ooh', 'want', 'need', \"can't\", 'stand', 'min...</td>\n",
              "      <td>ooh i don't want i don't need i can't stand no...</td>\n",
              "      <td>0.9942</td>\n",
              "      <td>0.009901</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>456 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0                       Song  ... Sentiment  Profanity\n",
              "1              1                       soft  ...   -0.9991   0.267327\n",
              "4              4                  black out  ...   -0.9987   0.198020\n",
              "5              5                    my will  ...   -0.9958   0.153465\n",
              "25            25                      damn!  ...    0.9992   0.420792\n",
              "27            27         whatchu lookin’ at  ...   -0.9978   0.242574\n",
              "...          ...                        ...  ...       ...        ...\n",
              "9154       11024  fuck what happens tonight  ...   -0.9995   0.366337\n",
              "9257       11167             one minute man  ...    0.4645   0.064356\n",
              "9260       11170               sock it 2 me  ...   -0.9879   0.143564\n",
              "9261       11171                 busa rhyme  ...   -0.9981   0.193069\n",
              "9262       11172     one minute man (remix)  ...    0.9942   0.009901\n",
              "\n",
              "[456 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NNt6E3Fe4Su",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "a2c236b2-c097-403b-eda2-e930cc2b6641"
      },
      "source": [
        "## input cell\r\n",
        "print(\"-------SmartLyrics Search Engine---------\")\r\n",
        "newdf = df\r\n",
        "artist = input('enter artist: ')\r\n",
        "album = input('enter album: ')\r\n",
        "startyear = (input('enter start year: '))\r\n",
        "endyear = (input('enter end year: '))\r\n",
        "lyrics = input('enter lyrics: ')\r\n",
        "sentiment = input('enter sentiment: ')\r\n",
        "profanity = input('enter profanity(explicit(1) not explicit(0): ')\r\n",
        "lyricSearch(filterbyartist(df,artist), lyrics)\r\n",
        "\r\n",
        "if artist == '':\r\n",
        "  pass\r\n",
        "else:\r\n",
        "  newdf = filterbyartist(newdf, artist)\r\n",
        "\r\n",
        "if album == '':\r\n",
        "  pass\r\n",
        "else:\r\n",
        "  newdf = filterbyalbum(newdf, album)\r\n",
        "\r\n",
        "if lyrics == '':\r\n",
        "  pass\r\n",
        "else:\r\n",
        "  newdf = lyricSearch(newdf, lyrics)\r\n",
        "\r\n",
        "if startyear == '' and endyear == '':\r\n",
        "  pass\r\n",
        "else:\r\n",
        "  newdf = filterbyyear(newdf, startyear, endyear)\r\n",
        "\r\n",
        "if sentiment == '':\r\n",
        "  pass\r\n",
        "else:\r\n",
        "  newdf = filterbysentiment(newdf, sentiment)\r\n",
        "\r\n",
        "if profanity == '':\r\n",
        "  pass\r\n",
        "else:\r\n",
        "  newdf = filterbysentiment(newdf, profanity)\r\n",
        "\r\n",
        "\r\n",
        "newdf\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------SmartLyrics Search Engine---------\n",
            "enter artist: drake\n",
            "enter album: scorpion\n",
            "enter start year: \n",
            "enter end year: \n",
            "enter lyrics: \n",
            "enter sentiment: happy\n",
            "enter profanity(explicit(1) not explicit(0): 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Song</th>\n",
              "      <th>Artist</th>\n",
              "      <th>Year</th>\n",
              "      <th>Album</th>\n",
              "      <th>Lyric</th>\n",
              "      <th>SentimentLyrics</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Profanity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1450</th>\n",
              "      <td>1499</td>\n",
              "      <td>god’s plan</td>\n",
              "      <td>drake</td>\n",
              "      <td>2018.0</td>\n",
              "      <td>scorpion</td>\n",
              "      <td>[\"wishin'\", \"wishin'\", \"wishin'\", \"wishin'\", \"...</td>\n",
              "      <td>and they wishin' and wishin' and wishin' and w...</td>\n",
              "      <td>0.932</td>\n",
              "      <td>0.024752</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0        Song  ... Sentiment  Profanity\n",
              "1450        1499  god’s plan  ...     0.932   0.024752\n",
              "\n",
              "[1 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zwDe7acqAst"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}